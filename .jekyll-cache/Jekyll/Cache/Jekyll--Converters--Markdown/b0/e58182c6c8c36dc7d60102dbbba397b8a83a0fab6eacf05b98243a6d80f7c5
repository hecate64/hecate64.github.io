I"ž<h2 id="publications">Publications</h2>

<div style="float: right"> <code>  </code> </div>

<p><strong>Accelerating Transformers with Fourier-Based Attention for Efficient On-Device Inference</strong> (submitted)</p>

<p>Hyeonjin Jo, Chaerin Sim, <em>Jaewoo Park</em>, Jongeun Lee
<br />
<br /></p>

<div style="float: right"> <code>  </code> </div>

<p><strong>Hyperdimensional Computing as a Rescue for Efficient Privacy-Preserving Machine Learning-as-a-Service</strong> (submitted)</p>

<p><em>Jaewoo Park</em>, Chenghao Quan, Hyungon Moon, Jongeun Lee
<br />
<br /></p>

<div style="float: right"> <code> DAC 2023 </code> </div>

<p><strong>NTT-PIM: Row-Centric Architecture and Mapping for Efficient Number-Theoretic Transform on PIM</strong></p>

<p><em>Jaewoo Park</em>, Sugil Lee, Jongeun Lee
<br />
<br /></p>

<div style="float: right"> <code> ICCAD 2022 </code> </div>

<p><strong><a href="https://dl.acm.org/doi/10.1145/3508352.3549418">Squeezing Accumulators in Binary Neural Network Accelerators</a></strong></p>

<p>Azat Azamat, <em>Jaewoo Park</em>, Jongeun Lee
<br />
<br /></p>

<div style="float: right"> <code> BMVC 2022 </code> </div>

<p><strong><a href="https://bmvc2022.mpi-inf.mpg.de/0538.pdf">Centered Symmetric Quantization for Hardware-Efficient Low-Bit Neural Networks</a></strong></p>

<p>Faaiz Asim*, <em>Jaewoo Park</em>*,  Jongeun Lee, Azat Azamat    <em>(* For equal contribution)</em>
<br />
<br /></p>
:ET